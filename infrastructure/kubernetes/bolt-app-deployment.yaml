# Bolt Application Deployment with Comprehensive Monitoring Sidecars
# Production-ready deployment with observability, security, and performance monitoring

apiVersion: v1
kind: Namespace
metadata:
  name: bolt-logging
  labels:
    name: bolt-logging
    monitoring: enabled
    istio-injection: enabled

---
apiVersion: v1
kind: ConfigMap
metadata:
  name: bolt-app-config
  namespace: bolt-logging
data:
  config.yaml: |
    app:
      name: bolt-logging-service
      version: "2.0.0"
      port: 8080
      environment: production
      
    logging:
      level: info
      format: json
      zero_allocation: true
      performance_target_ns: 100000  # 100μs SLA
      
    metrics:
      enabled: true
      port: 9090
      path: /metrics
      
    tracing:
      enabled: true
      jaeger_endpoint: "http://jaeger-collector:14268/api/traces"
      sampling_rate: 0.1
      
    health:
      port: 8081
      liveness_path: /health/live
      readiness_path: /health/ready

---
apiVersion: v1
kind: ServiceAccount
metadata:
  name: bolt-app
  namespace: bolt-logging
  annotations:
    eks.amazonaws.com/role-arn: arn:aws:iam::ACCOUNT_ID:role/bolt-app-role

---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: bolt-app
  namespace: bolt-logging
  labels:
    app: bolt-app
    version: v2.0.0
    component: logging-service
  annotations:
    deployment.kubernetes.io/revision: "1"
spec:
  replicas: 3
  strategy:
    type: RollingUpdate
    rollingUpdate:
      maxUnavailable: 1
      maxSurge: 1
  selector:
    matchLabels:
      app: bolt-app
      version: v2.0.0
  template:
    metadata:
      labels:
        app: bolt-app
        version: v2.0.0
        component: logging-service
      annotations:
        # Prometheus scraping annotations
        prometheus.io/scrape: "true"
        prometheus.io/port: "9090"
        prometheus.io/path: "/metrics"
        
        # Jaeger tracing annotations
        sidecar.jaegertracing.io/inject: "true"
        
        # Istio sidecar annotations
        sidecar.istio.io/inject: "true"
        sidecar.istio.io/proxyCPULimit: "100m"
        sidecar.istio.io/proxyMemoryLimit: "128Mi"
        
        # Configuration version for rolling restarts
        configmap.hash: "{{ include (print $.Template.BasePath \"/configmap.yaml\") . | sha256sum }}"
    spec:
      serviceAccountName: bolt-app
      
      # Security context
      securityContext:
        runAsNonRoot: true
        runAsUser: 1000
        runAsGroup: 3000
        fsGroup: 2000
        seccompProfile:
          type: RuntimeDefault
      
      # Resource optimization for Bolt's performance requirements
      priorityClassName: high-priority
      
      # Pod affinity for optimal performance
      affinity:
        podAntiAffinity:
          preferredDuringSchedulingIgnoredDuringExecution:
          - weight: 100
            podAffinityTerm:
              labelSelector:
                matchExpressions:
                - key: app
                  operator: In
                  values: ["bolt-app"]
              topologyKey: kubernetes.io/hostname
        nodeAffinity:
          preferredDuringSchedulingIgnoredDuringExecution:
          - weight: 100
            preference:
              matchExpressions:
              - key: node-type
                operator: In
                values: ["compute-optimized"]
      
      # Init container for setup
      initContainers:
      - name: init-setup
        image: busybox:1.35
        command: ['sh', '-c']
        args:
        - |
          echo "Initializing Bolt application..."
          echo "Checking configuration validity..."
          if [ -f /config/config.yaml ]; then
            echo "Configuration found and validated"
          else
            echo "Configuration missing!" && exit 1
          fi
        volumeMounts:
        - name: config-volume
          mountPath: /config
          readOnly: true
        securityContext:
          allowPrivilegeEscalation: false
          capabilities:
            drop:
            - ALL
          readOnlyRootFilesystem: true
      
      containers:
      # Main Bolt application container
      - name: bolt-app
        image: bolt-logging/app:v2.0.0
        imagePullPolicy: IfNotPresent
        
        ports:
        - name: http
          containerPort: 8080
          protocol: TCP
        - name: metrics
          containerPort: 9090
          protocol: TCP
        - name: health
          containerPort: 8081
          protocol: TCP
        
        env:
        - name: CONFIG_PATH
          value: "/config/config.yaml"
        - name: POD_NAME
          valueFrom:
            fieldRef:
              fieldPath: metadata.name
        - name: POD_NAMESPACE
          valueFrom:
            fieldRef:
              fieldPath: metadata.namespace
        - name: POD_IP
          valueFrom:
            fieldRef:
              fieldPath: status.podIP
        - name: NODE_NAME
          valueFrom:
            fieldRef:
              fieldPath: spec.nodeName
        
        # Resource limits optimized for Bolt's zero-allocation performance
        resources:
          requests:
            cpu: "500m"
            memory: "256Mi"
            ephemeral-storage: "1Gi"
          limits:
            cpu: "2000m"
            memory: "1Gi"
            ephemeral-storage: "2Gi"
        
        # Security context for container
        securityContext:
          allowPrivilegeEscalation: false
          capabilities:
            drop:
            - ALL
          readOnlyRootFilesystem: true
          runAsNonRoot: true
          runAsUser: 1000
        
        # Volume mounts
        volumeMounts:
        - name: config-volume
          mountPath: /config
          readOnly: true
        - name: tmp-volume
          mountPath: /tmp
        - name: logs-volume
          mountPath: /app/logs
        
        # Health checks
        livenessProbe:
          httpGet:
            path: /health/live
            port: health
          initialDelaySeconds: 30
          periodSeconds: 10
          timeoutSeconds: 5
          failureThreshold: 3
          successThreshold: 1
        
        readinessProbe:
          httpGet:
            path: /health/ready
            port: health
          initialDelaySeconds: 5
          periodSeconds: 5
          timeoutSeconds: 3
          failureThreshold: 3
          successThreshold: 1
        
        # Startup probe for graceful initialization
        startupProbe:
          httpGet:
            path: /health/ready
            port: health
          initialDelaySeconds: 10
          periodSeconds: 5
          timeoutSeconds: 3
          failureThreshold: 30
          successThreshold: 1
      
      # Monitoring sidecar: Node Exporter for system metrics
      - name: node-exporter-sidecar
        image: prom/node-exporter:v1.6.1
        args:
        - --path.procfs=/host/proc
        - --path.sysfs=/host/sys
        - --path.rootfs=/host/root
        - --collector.filesystem.mount-points-exclude=^/(sys|proc|dev|host|etc)($$|/)
        ports:
        - name: node-metrics
          containerPort: 9100
          protocol: TCP
        resources:
          requests:
            cpu: "50m"
            memory: "64Mi"
          limits:
            cpu: "200m"
            memory: "128Mi"
        securityContext:
          allowPrivilegeEscalation: false
          capabilities:
            drop:
            - ALL
          readOnlyRootFilesystem: true
        volumeMounts:
        - name: proc
          mountPath: /host/proc
          readOnly: true
        - name: sys
          mountPath: /host/sys
          readOnly: true
        - name: root
          mountPath: /host/root
          readOnly: true
      
      # Log aggregation sidecar: Fluentd for log shipping
      - name: fluentd-sidecar
        image: fluent/fluentd:v1.16-debian-1
        env:
        - name: FLUENTD_CONF
          value: "fluentd.conf"
        - name: FLUENT_ELASTICSEARCH_HOST
          value: "elasticsearch.monitoring.svc.cluster.local"
        - name: FLUENT_ELASTICSEARCH_PORT
          value: "9200"
        - name: FLUENT_ELASTICSEARCH_INDEX_NAME
          value: "bolt-logs"
        resources:
          requests:
            cpu: "100m"
            memory: "128Mi"
          limits:
            cpu: "500m"
            memory: "256Mi"
        securityContext:
          allowPrivilegeEscalation: false
          capabilities:
            drop:
            - ALL
        volumeMounts:
        - name: fluentd-config
          mountPath: /fluentd/etc
          readOnly: true
        - name: logs-volume
          mountPath: /app/logs
          readOnly: true
      
      # Security monitoring sidecar: Falco for runtime security
      - name: falco-sidecar
        image: falcosecurity/falco-no-driver:0.36.0
        args:
        - /usr/bin/falco
        - --cri=/run/containerd/containerd.sock
        - --k8s-api
        - --k8s-api-cert=/var/run/secrets/kubernetes.io/serviceaccount/ca.crt
        - --k8s-api-token=/var/run/secrets/kubernetes.io/serviceaccount/token
        - -pk
        resources:
          requests:
            cpu: "100m"
            memory: "128Mi"
          limits:
            cpu: "200m"
            memory: "256Mi"
        securityContext:
          privileged: false
          allowPrivilegeEscalation: false
          capabilities:
            drop:
            - ALL
            add:
            - SYS_PTRACE
        volumeMounts:
        - name: containerd-socket
          mountPath: /run/containerd/containerd.sock
          readOnly: true
        - name: falco-config
          mountPath: /etc/falco
          readOnly: true
      
      # Performance monitoring sidecar: Custom Bolt metrics collector
      - name: bolt-metrics-collector
        image: bolt-logging/metrics-collector:v1.0.0
        ports:
        - name: bolt-metrics
          containerPort: 9091
          protocol: TCP
        env:
        - name: BOLT_APP_ENDPOINT
          value: "http://localhost:9090/metrics"
        - name: COLLECTION_INTERVAL
          value: "1s"
        - name: ZERO_ALLOCATION_THRESHOLD
          value: "0"
        - name: LATENCY_SLA_NS
          value: "100000"  # 100μs SLA
        resources:
          requests:
            cpu: "50m"
            memory: "64Mi"
          limits:
            cpu: "100m"
            memory: "128Mi"
        securityContext:
          allowPrivilegeEscalation: false
          capabilities:
            drop:
            - ALL
          readOnlyRootFilesystem: true
      
      # Terminate gracefully
      terminationGracePeriodSeconds: 30
      
      # Volumes
      volumes:
      - name: config-volume
        configMap:
          name: bolt-app-config
          defaultMode: 0644
      - name: tmp-volume
        emptyDir:
          sizeLimit: 1Gi
      - name: logs-volume
        emptyDir:
          sizeLimit: 2Gi
      - name: proc
        hostPath:
          path: /proc
      - name: sys
        hostPath:
          path: /sys
      - name: root
        hostPath:
          path: /
      - name: containerd-socket
        hostPath:
          path: /run/containerd/containerd.sock
      - name: fluentd-config
        configMap:
          name: fluentd-config
      - name: falco-config
        configMap:
          name: falco-config

---
# Service for Bolt application
apiVersion: v1
kind: Service
metadata:
  name: bolt-app-service
  namespace: bolt-logging
  labels:
    app: bolt-app
    service: bolt-logging
  annotations:
    prometheus.io/scrape: "true"
    prometheus.io/port: "9090"
    prometheus.io/path: "/metrics"
spec:
  type: ClusterIP
  ports:
  - name: http
    port: 80
    targetPort: http
    protocol: TCP
  - name: metrics
    port: 9090
    targetPort: metrics
    protocol: TCP
  - name: health
    port: 8081
    targetPort: health
    protocol: TCP
  - name: node-metrics
    port: 9100
    targetPort: node-metrics
    protocol: TCP
  - name: bolt-metrics
    port: 9091
    targetPort: bolt-metrics
    protocol: TCP
  selector:
    app: bolt-app
    version: v2.0.0

---
# ServiceMonitor for Prometheus auto-discovery
apiVersion: monitoring.coreos.com/v1
kind: ServiceMonitor
metadata:
  name: bolt-app-monitor
  namespace: bolt-logging
  labels:
    app: bolt-app
    prometheus: kube-prometheus
spec:
  selector:
    matchLabels:
      app: bolt-app
  endpoints:
  - port: metrics
    path: /metrics
    interval: 1s
    scrapeTimeout: 500ms
  - port: node-metrics
    path: /metrics
    interval: 5s
    scrapeTimeout: 3s
  - port: bolt-metrics
    path: /metrics
    interval: 1s
    scrapeTimeout: 500ms

---
# HorizontalPodAutoscaler for performance-based scaling
apiVersion: autoscaling/v2
kind: HorizontalPodAutoscaler
metadata:
  name: bolt-app-hpa
  namespace: bolt-logging
spec:
  scaleTargetRef:
    apiVersion: apps/v1
    kind: Deployment
    name: bolt-app
  minReplicas: 3
  maxReplicas: 20
  metrics:
  - type: Resource
    resource:
      name: cpu
      target:
        type: Utilization
        averageUtilization: 70
  - type: Resource
    resource:
      name: memory
      target:
        type: Utilization
        averageUtilization: 80
  # Custom metrics for Bolt-specific scaling
  - type: Pods
    pods:
      metric:
        name: bolt_logging_rate
      target:
        type: AverageValue
        averageValue: "50000"  # Scale when >50k logs/sec per pod
  - type: Pods
    pods:
      metric:
        name: bolt_logging_latency_p95
      target:
        type: AverageValue
        averageValue: "90000n"  # Scale when p95 latency >90μs
  behavior:
    scaleDown:
      stabilizationWindowSeconds: 300
      policies:
      - type: Percent
        value: 10
        periodSeconds: 60
    scaleUp:
      stabilizationWindowSeconds: 60
      policies:
      - type: Percent
        value: 50
        periodSeconds: 30
      - type: Pods
        value: 2
        periodSeconds: 30

---
# PodDisruptionBudget for high availability
apiVersion: policy/v1
kind: PodDisruptionBudget
metadata:
  name: bolt-app-pdb
  namespace: bolt-logging
spec:
  minAvailable: 2
  selector:
    matchLabels:
      app: bolt-app
      version: v2.0.0

---
# NetworkPolicy for security
apiVersion: networking.k8s.io/v1
kind: NetworkPolicy
metadata:
  name: bolt-app-netpol
  namespace: bolt-logging
spec:
  podSelector:
    matchLabels:
      app: bolt-app
  policyTypes:
  - Ingress
  - Egress
  ingress:
  # Allow traffic from Istio gateway
  - from:
    - namespaceSelector:
        matchLabels:
          name: istio-system
    ports:
    - protocol: TCP
      port: 8080
  # Allow Prometheus scraping
  - from:
    - namespaceSelector:
        matchLabels:
          name: monitoring
    ports:
    - protocol: TCP
      port: 9090
    - protocol: TCP
      port: 9091
    - protocol: TCP
      port: 9100
  egress:
  # Allow DNS
  - to: []
    ports:
    - protocol: UDP
      port: 53
  # Allow communication to Jaeger
  - to:
    - namespaceSelector:
        matchLabels:
          name: monitoring
    ports:
    - protocol: TCP
      port: 14268
  # Allow communication to external services
  - to: []
    ports:
    - protocol: TCP
      port: 443
    - protocol: TCP
      port: 80