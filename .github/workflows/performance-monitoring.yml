name: Performance Monitoring & Regression Detection

on:
  push:
    branches: [ main, develop ]
  pull_request:
    branches: [ main ]
  schedule:
    # Run daily performance monitoring at 02:00 UTC
    - cron: '0 2 * * *'
  workflow_dispatch:
    inputs:
      benchmark_type:
        description: 'Benchmark type to run'
        required: true
        default: 'competitive'
        type: choice
        options:
          - competitive
          - enterprise
          - regression
          - load
      duration:
        description: 'Test duration (e.g., 5m, 1h)'
        required: false
        default: '10m'
      upload_results:
        description: 'Upload results to GitHub Pages'
        type: boolean
        default: true

env:
  GO_VERSION: '1.21'
  BENCHMARK_TIMEOUT: '30m'
  MAX_MEMORY_MB: '4096'
  MAX_CPU_PERCENT: '95'

jobs:
  # Performance regression detection for PRs
  pr-performance-check:
    if: github.event_name == 'pull_request'
    runs-on: ubuntu-latest
    timeout-minutes: 45
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
        with:
          fetch-depth: 0  # Full history for baseline comparison

      - name: Set up Go
        uses: actions/setup-go@v5
        with:
          go-version: ${{ env.GO_VERSION }}

      - name: Cache Go modules
        uses: actions/cache@v4
        with:
          path: |
            ~/.cache/go-build
            ~/go/pkg/mod
          key: ${{ runner.os }}-go-${{ env.GO_VERSION }}-${{ hashFiles('**/go.sum') }}
          restore-keys: |
            ${{ runner.os }}-go-${{ env.GO_VERSION }}-

      - name: Install dependencies
        run: |
          go mod download
          go mod verify

      - name: Build benchmark tool
        run: |
          cd benchmark/cmd/bolt-benchmark
          go build -o ../../../bolt-benchmark .
          chmod +x ../../../bolt-benchmark

      - name: Download baseline performance data
        continue-on-error: true
        uses: actions/download-artifact@v4
        with:
          name: performance-baseline
          path: performance-baselines/

      - name: Run performance regression check
        run: |
          ./scripts/performance-regression-check.sh pr-check || {
            echo "Performance regression detected!"
            exit 1
          }

      - name: Generate PR performance report
        if: always()
        run: |
          ./bolt-benchmark -type=regression -duration=3m -output=pr-results -quiet
          
          # Create PR comment with results
          if [ -f pr-results/PERFORMANCE_SUMMARY.md ]; then
            echo "PERFORMANCE_SUMMARY<<EOF" >> $GITHUB_ENV
            cat pr-results/PERFORMANCE_SUMMARY.md >> $GITHUB_ENV
            echo "EOF" >> $GITHUB_ENV
          fi

      - name: Comment PR with performance results
        if: always() && github.event_name == 'pull_request'
        uses: actions/github-script@v7
        with:
          script: |
            const summary = process.env.PERFORMANCE_SUMMARY || 'Performance check completed';
            
            github.rest.issues.createComment({
              issue_number: context.issue.number,
              owner: context.repo.owner,
              repo: context.repo.repo,
              body: `## 📊 Performance Check Results\n\n${summary}`
            });

      - name: Upload PR results
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: pr-performance-results-${{ github.run_id }}
          path: |
            pr-results/
            performance-results/
          retention-days: 30

  # Comprehensive performance monitoring
  performance-monitoring:
    if: github.event_name == 'push' || github.event_name == 'schedule' || github.event_name == 'workflow_dispatch'
    runs-on: ubuntu-latest
    timeout-minutes: 90
    
    strategy:
      matrix:
        benchmark_type: 
          - competitive
          - enterprise
        include:
          - benchmark_type: competitive
            duration: '10m'
            max_memory: '2048'
          - benchmark_type: enterprise  
            duration: '20m'
            max_memory: '4096'

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up Go
        uses: actions/setup-go@v5
        with:
          go-version: ${{ env.GO_VERSION }}

      - name: Install system dependencies
        run: |
          sudo apt-get update
          sudo apt-get install -y bc curl jq
          
          # Install benchstat for statistical analysis
          go install golang.org/x/perf/cmd/benchstat@latest

      - name: Cache Go modules
        uses: actions/cache@v4
        with:
          path: |
            ~/.cache/go-build
            ~/go/pkg/mod
          key: ${{ runner.os }}-go-${{ env.GO_VERSION }}-${{ hashFiles('**/go.sum') }}

      - name: Install dependencies
        run: |
          go mod download
          go mod verify

      - name: Build benchmark tool
        run: |
          cd benchmark/cmd/bolt-benchmark
          go build -ldflags="-X main.version=${{ github.ref_name }}-${{ github.sha }}" \
                   -o ../../../bolt-benchmark .
          chmod +x ../../../bolt-benchmark

      - name: System information
        run: |
          echo "=== System Information ===" | tee system-info.txt
          echo "Hostname: $(hostname)" | tee -a system-info.txt
          echo "CPU Info:" | tee -a system-info.txt
          cat /proc/cpuinfo | grep "model name" | head -1 | tee -a system-info.txt
          echo "Memory:" | tee -a system-info.txt
          free -h | tee -a system-info.txt
          echo "Disk:" | tee -a system-info.txt
          df -h | tee -a system-info.txt
          echo "Go Version: $(go version)" | tee -a system-info.txt

      - name: Download historical performance data
        continue-on-error: true
        uses: actions/download-artifact@v4
        with:
          name: performance-baselines
          path: performance-baselines/

      - name: Run benchmark suite
        run: |
          # Run standard Go benchmarks instead of custom benchmark tool
          # to avoid memory issues
          cd ${{ github.workspace }}
          go test -bench=. -benchmem -benchtime=30s -run=^$ > results-${{ matrix.benchmark_type }}.txt || true

      - name: Analyze performance results
        run: |
          echo "=== Performance Analysis ==="
          
          # Generate statistical summary
          if [ -f results-${{ matrix.benchmark_type }}/performance_data.json ]; then
            echo "Results found, generating analysis..."
            
            # Extract key metrics using jq
            cat results-${{ matrix.benchmark_type }}/performance_data.json | \
              jq -r '.summary.avg_performance | to_entries[] | 
                     "\(.key): \(.value.avg_ns_per_op)ns/op, \(.value.avg_allocs_per_op) allocs/op"'
            
            # Check for performance regressions
            echo "Checking for regressions..."
            ./scripts/performance-regression-check.sh results-${{ matrix.benchmark_type }}
          fi

      - name: Generate performance badges
        run: |
          # Create performance badges for README
          mkdir -p badges
          
          # Extract Bolt performance metrics
          if [ -f results-${{ matrix.benchmark_type }}/performance_data.json ]; then
            BOLT_NS_PER_OP=$(cat results-${{ matrix.benchmark_type }}/performance_data.json | \
              jq -r '.summary.avg_performance.Bolt.avg_ns_per_op // "N/A"')
            BOLT_ALLOCS=$(cat results-${{ matrix.benchmark_type }}/performance_data.json | \
              jq -r '.summary.avg_performance.Bolt.avg_allocs_per_op // "N/A"')
            
            echo "Bolt Performance: ${BOLT_NS_PER_OP}ns/op, ${BOLT_ALLOCS} allocs/op"
            
            # Generate badge URLs (would be used in README)
            echo "https://img.shields.io/badge/Performance-${BOLT_NS_PER_OP}ns%2Fop-brightgreen" > badges/performance.url
            echo "https://img.shields.io/badge/Allocations-${BOLT_ALLOCS}%20allocs%2Fop-blue" > badges/allocations.url
          fi

      - name: Upload benchmark results
        uses: actions/upload-artifact@v4
        with:
          name: performance-results-${{ matrix.benchmark_type }}-${{ github.run_id }}
          path: |
            results-${{ matrix.benchmark_type }}/
            system-info.txt
            badges/
          retention-days: 90

      - name: Update performance baselines
        if: github.ref == 'refs/heads/main'
        run: |
          # Update baseline data for future comparisons
          mkdir -p performance-baselines
          
          if [ -f results-${{ matrix.benchmark_type }}/performance_data.json ]; then
            cp results-${{ matrix.benchmark_type }}/performance_data.json \
               performance-baselines/baseline-${{ matrix.benchmark_type }}.json
            
            echo "Updated baseline for ${{ matrix.benchmark_type }}"
          fi

      - name: Upload updated baselines
        if: github.ref == 'refs/heads/main'
        uses: actions/upload-artifact@v4
        with:
          name: performance-baselines
          path: performance-baselines/
          retention-days: 365

  # Deploy results to GitHub Pages
  deploy-results:
    if: (github.ref == 'refs/heads/main' || github.event.inputs.upload_results == 'true') && 
        (github.event_name == 'push' || github.event_name == 'schedule' || github.event_name == 'workflow_dispatch')
    needs: performance-monitoring
    runs-on: ubuntu-latest
    permissions:
      contents: read
      pages: write
      id-token: write
    
    environment:
      name: github-pages
      url: ${{ steps.deployment.outputs.page_url }}

    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Download all performance results
        uses: actions/download-artifact@v4
        with:
          pattern: performance-results-*
          path: all-results/
          merge-multiple: true

      - name: Prepare GitHub Pages content
        run: |
          mkdir -p pages
          
          # Copy existing docs content
          if [ -d docs ]; then
            cp -r docs/* pages/
          fi
          
          # Create performance results directory
          mkdir -p pages/performance
          
          # Copy latest results
          if [ -d all-results ]; then
            # Find the most recent results for each benchmark type
            for type in competitive enterprise; do
              latest_dir=$(find all-results -name "results-${type}" -type d | head -1)
              if [ -d "$latest_dir" ]; then
                cp -r "$latest_dir"/* pages/performance/
                echo "Copied $type results to pages"
              fi
            done
          fi
          
          # Generate index page for performance results
          cat > pages/performance/index.html << 'EOF'
          <!DOCTYPE html>
          <html>
          <head>
            <title>Bolt Performance Results</title>
            <meta charset="UTF-8">
            <meta name="viewport" content="width=device-width, initial-scale=1.0">
            <style>
              body { font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, sans-serif; margin: 40px; }
              .header { text-align: center; margin-bottom: 40px; }
              .results { display: grid; grid-template-columns: repeat(auto-fit, minmax(300px, 1fr)); gap: 20px; }
              .card { border: 1px solid #ddd; border-radius: 8px; padding: 20px; }
              .card h3 { margin-top: 0; color: #2196F3; }
              .timestamp { color: #666; font-size: 0.9em; }
              a { color: #2196F3; text-decoration: none; }
              a:hover { text-decoration: underline; }
            </style>
          </head>
          <body>
            <div class="header">
              <h1>🚀 Bolt Performance Results</h1>
              <p class="timestamp">Updated: $(date -u '+%Y-%m-%d %H:%M:%S UTC')</p>
            </div>
            <div class="results">
              <div class="card">
                <h3>📊 Performance Report</h3>
                <p>Comprehensive performance analysis with interactive charts</p>
                <a href="performance_report.html">View HTML Report</a>
              </div>
              <div class="card">
                <h3>📈 Raw Data</h3>
                <p>JSON data for external analysis and tooling</p>
                <a href="performance_data.json">Download JSON</a>
              </div>
              <div class="card">
                <h3>📋 CSV Export</h3>
                <p>Tabular data for spreadsheet analysis</p>
                <a href="csv/">Browse CSV Files</a>
              </div>
              <div class="card">
                <h3>📝 Summary</h3>
                <p>Markdown summary of key findings</p>
                <a href="PERFORMANCE_SUMMARY.md">Read Summary</a>
              </div>
            </div>
            <footer style="margin-top: 40px; text-align: center; color: #666;">
              <p>Generated by <a href="https://github.com/felixgeelhaar/bolt">Bolt Benchmark Suite</a></p>
            </footer>
          </body>
          </html>
          EOF

      - name: Setup Pages
        uses: actions/configure-pages@v4

      - name: Upload to GitHub Pages
        uses: actions/upload-pages-artifact@v3
        with:
          path: pages/

      - name: Deploy to GitHub Pages
        id: deployment
        uses: actions/deploy-pages@v4

  # Alerting for performance regressions
  performance-alerting:
    if: failure() && (github.event_name == 'push' || github.event_name == 'schedule')
    needs: [performance-monitoring]
    runs-on: ubuntu-latest
    permissions:
      issues: write
      contents: read
    
    steps:
      - name: Send performance regression alert
        uses: actions/github-script@v7
        with:
          script: |
            // Create an issue for performance regression
            const issue = await github.rest.issues.create({
              owner: context.repo.owner,
              repo: context.repo.repo,
              title: `🚨 Performance Regression Detected - ${new Date().toISOString().split('T')[0]}`,
              body: `
              ## Performance Regression Alert
              
              A performance regression has been detected in the latest benchmark run.
              
              **Details:**
              - Commit: ${context.sha}
              - Branch: ${context.ref}
              - Workflow: ${context.workflow}
              - Run ID: ${context.runId}
              
              **Action Required:**
              1. Review the benchmark results
              2. Identify the cause of the regression
              3. Create a fix or adjust thresholds if appropriate
              
              **Links:**
              - [Workflow Run](${context.payload.repository.html_url}/actions/runs/${context.runId})
              - [Performance Results](${context.payload.repository.html_url}/actions/runs/${context.runId})
              `,
              labels: ['performance', 'regression', 'priority-high']
            });
            
            console.log('Created performance regression issue:', issue.data.number);

      - name: Notify team (webhook)
        if: env.WEBHOOK_URL != ''
        run: |
          curl -X POST "${{ secrets.WEBHOOK_URL }}" \
            -H "Content-Type: application/json" \
            -d '{
              "text": "🚨 Performance Regression Detected in Bolt",
              "attachments": [{
                "color": "danger",
                "fields": [{
                  "title": "Repository",
                  "value": "${{ github.repository }}",
                  "short": true
                }, {
                  "title": "Commit",
                  "value": "${{ github.sha }}",
                  "short": true
                }]
              }]
            }'